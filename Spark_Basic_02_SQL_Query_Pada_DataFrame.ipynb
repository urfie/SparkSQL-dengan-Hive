{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vJbZRSkkTnAw"
   },
   "source": [
    "SQL adalah salah satu bahasa populer untuk pemrosesan dan analisis data. Spark mendukung SQL untuk memproses DataFrame.\n",
    "\n",
    "Kita akan menggunakan data yang sama dengan yg digunakan pada bab eksplorasi DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xyqGzlLOuBpV",
    "outputId": "8db700a3-5a01-4cff-dfd5-14cedc30d292"
   },
   "outputs": [],
   "source": [
    "#%pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "qJDNbI5gti9B"
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HgEv2iNhTitC"
   },
   "source": [
    "Inisialisasi spark session untuk berinteraksi dengan Spark cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Hnxed8rpt5Xs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/10/07 00:38:00 WARN Utils: Your hostname, dl247-virtual-machine resolves to a loopback address: 127.0.1.1; using 192.168.15.135 instead (on interface ens33)\n",
      "23/10/07 00:38:00 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/10/07 00:38:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('DataFrame Basics').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iHGCn-voUTzn"
   },
   "source": [
    "Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PQTqnwezHtSq",
    "outputId": "b10fcac7-d661-4c96-bc8a-c2ca6ac19b76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-10-07 00:38:13--  https://github.com/urfie/SparkSQL-dengan-Hive/raw/main/datasets/application_record_header.csv.gz\n",
      "Resolving github.com (github.com)... 20.205.243.166\n",
      "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/urfie/SparkSQL-dengan-Hive/main/datasets/application_record_header.csv.gz [following]\n",
      "--2023-10-07 00:38:14--  https://raw.githubusercontent.com/urfie/SparkSQL-dengan-Hive/main/datasets/application_record_header.csv.gz\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3175443 (3,0M) [application/octet-stream]\n",
      "Saving to: ‘application_record_header.csv.gz’\n",
      "\n",
      "application_record_ 100%[===================>]   3,03M  3,03MB/s    in 1,0s    \n",
      "\n",
      "2023-10-07 00:38:16 (3,03 MB/s) - ‘application_record_header.csv.gz’ saved [3175443/3175443]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!wget https://raw.githubusercontent.com/urfie/SparkSQL-dengan-Hive/main/datasets/indonesia2013-2015.csv\n",
    "!wget https://github.com/urfie/SparkSQL-dengan-Hive/raw/main/datasets/application_record_header.csv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-vEl7qY6UV4Y"
   },
   "source": [
    "Load ke dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ArREYTQWHy3J"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"application_record_header.csv.gz\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lvgyM2iKUYS9"
   },
   "source": [
    "Sebelum menggunakan SQL, kita perlu membuat temporary table dari dataframe yang akan kita olah.\n",
    "\n",
    "Gunakan fungsi `createOrReplaceTempView(nama_tabel)` pada dataframe tersebut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "29qI_YUJnF_N"
   },
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"app_record\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xuijaPcEUz3g"
   },
   "source": [
    "Selanjutnya kita bisa menggunakan nama tabel yang sudah kita definisikan dalam SQL statement.\n",
    "\n",
    "Untuk mengeksekusi SQL statement, kita gunakan fungsi `sql(sqlstatement)` pada spark session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mEZWLQbtnIHX",
    "outputId": "b42fefee-416b-44fb-ada7-a35dff9ac7ad"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|  438557|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select count(*) from app_record\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6fLoE47EnMtP",
    "outputId": "f57b491c-d817-4fdb-f89d-043e43584e25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+------------+---------------+------------+----------------+--------------------+--------------------+--------------------+-----------------+----------+-------------+----------+---------------+----------+----------+---------------+---------------+\n",
      "|     ID|CODE_GENDER|FLAG_OWN_CAR|FLAG_OWN_REALTY|CNT_CHILDREN|AMT_INCOME_TOTAL|    NAME_INCOME_TYPE| NAME_EDUCATION_TYPE|  NAME_FAMILY_STATUS|NAME_HOUSING_TYPE|DAYS_BIRTH|DAYS_EMPLOYED|FLAG_MOBIL|FLAG_WORK_PHONE|FLAG_PHONE|FLAG_EMAIL|OCCUPATION_TYPE|CNT_FAM_MEMBERS|\n",
      "+-------+-----------+------------+---------------+------------+----------------+--------------------+--------------------+--------------------+-----------------+----------+-------------+----------+---------------+----------+----------+---------------+---------------+\n",
      "|5008804|          M|           Y|              Y|           0|        427500.0|             Working|    Higher education|      Civil marriage| Rented apartment|    -12005|        -4542|         1|              1|         0|         0|           null|            2.0|\n",
      "|5008805|          M|           Y|              Y|           0|        427500.0|             Working|    Higher education|      Civil marriage| Rented apartment|    -12005|        -4542|         1|              1|         0|         0|           null|            2.0|\n",
      "|5008806|          M|           Y|              Y|           0|        112500.0|             Working|Secondary / secon...|             Married|House / apartment|    -21474|        -1134|         1|              0|         0|         0| Security staff|            2.0|\n",
      "|5008808|          F|           N|              Y|           0|        270000.0|Commercial associate|Secondary / secon...|Single / not married|House / apartment|    -19110|        -3051|         1|              0|         1|         1|    Sales staff|            1.0|\n",
      "|5008809|          F|           N|              Y|           0|        270000.0|Commercial associate|Secondary / secon...|Single / not married|House / apartment|    -19110|        -3051|         1|              0|         1|         1|    Sales staff|            1.0|\n",
      "+-------+-----------+------------+---------------+------------+----------------+--------------------+--------------------+--------------------+-----------------+----------+-------------+----------+---------------+----------+----------+---------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from app_record limit 5\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xbCMW4oP7JbI",
    "outputId": "171af78d-d96d-4999-cb52-611afc35efa3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+\n",
      "|NAME_EDUCATION_TYPE          |\n",
      "+-----------------------------+\n",
      "|Academic degree              |\n",
      "|Incomplete higher            |\n",
      "|Secondary / secondary special|\n",
      "|Lower secondary              |\n",
      "|Higher education             |\n",
      "+-----------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select distinct NAME_EDUCATION_TYPE from app_record\").show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "py7cZ3yF7INt",
    "outputId": "64dd343f-c15c-4b0b-9824-59ad6e9ec2df"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+\n",
      "| NAME_EDUCATION_TYPE|EDU_LEVEL|\n",
      "+--------------------+---------+\n",
      "|     Academic degree|        3|\n",
      "|   Incomplete higher|        4|\n",
      "|Secondary / secon...|        2|\n",
      "|     Lower secondary|        1|\n",
      "|    Higher education|        5|\n",
      "+--------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mydata = (('Academic degree',3),\n",
    "    ('Incomplete higher',4),\n",
    "    ('Secondary / secondary special',2),\n",
    "    ('Lower secondary',1),\n",
    "    ('Higher education',5))\n",
    "\n",
    "ref_edu = spark.createDataFrame(mydata).toDF(\"NAME_EDUCATION_TYPE\", \"EDU_LEVEL\")\n",
    "ref_edu.createOrReplaceTempView(\"ref_edu\")\n",
    "spark.sql(\"select * from ref_edu\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "IkuuNd0ynWll"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT edu_level, count(1) FROM\n",
    "              (SELECT ref_edu.EDU_LEVEL as edu_level\n",
    "                FROM app_record LEFT JOIN ref_edu\n",
    "                ON app_record.NAME_EDUCATION_TYPE=ref_edu.NAME_EDUCATION_TYPE)\n",
    "             GROUP BY edu_level SORT BY edu_level\"\"\").write.saveAsTable(name=\"aggregated_edu\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ysuMyldWC59p"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------+-----------+\n",
      "|namespace|     tableName|isTemporary|\n",
      "+---------+--------------+-----------+\n",
      "|  default|aggregated_edu|      false|\n",
      "|         |    app_record|       true|\n",
      "|         |       ref_edu|       true|\n",
      "+---------+--------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show tables\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+--------------------------------------------------------+-------+\n",
      "|col_name                    |data_type                                               |comment|\n",
      "+----------------------------+--------------------------------------------------------+-------+\n",
      "|edu_level                   |bigint                                                  |null   |\n",
      "|count(1)                    |bigint                                                  |null   |\n",
      "|                            |                                                        |       |\n",
      "|# Detailed Table Information|                                                        |       |\n",
      "|Database                    |default                                                 |       |\n",
      "|Table                       |aggregated_edu                                          |       |\n",
      "|Created Time                |Sat Oct 07 00:39:23 WIB 2023                            |       |\n",
      "|Last Access                 |UNKNOWN                                                 |       |\n",
      "|Created By                  |Spark 3.3.3                                             |       |\n",
      "|Type                        |MANAGED                                                 |       |\n",
      "|Provider                    |parquet                                                 |       |\n",
      "|Location                    |hdfs://localhost:9000/user/hive/warehouse/aggregated_edu|       |\n",
      "+----------------------------+--------------------------------------------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"describe formatted aggregated_edu\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
